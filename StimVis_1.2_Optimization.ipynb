{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedWindow(verbose=True): could not load k3d module, try:\n",
      "> pip install k3d      # and if necessary:\n",
      "> conda install nodejs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from dipy.io.streamline import load_trk\n",
    "from dipy.io.image import load_nifti, save_nifti\n",
    "\n",
    "from dipy.viz import regtools\n",
    "from dipy.viz import actor, window, ui\n",
    "from dipy.align.imaffine import (transform_centers_of_mass,\n",
    "                                 AffineMap,\n",
    "                                 MutualInformationMetric,\n",
    "                                 AffineRegistration)\n",
    "from dipy.align.transforms import (TranslationTransform3D,\n",
    "                                   RigidTransform3D,\n",
    "                                   AffineTransform3D)\n",
    "\n",
    "from dipy.tracking import streamline\n",
    "\n",
    "import simnibs\n",
    "from simnibs import sim_struct, run_simnibs\n",
    "\n",
    "import vtkplotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, specify the file with tracts that you would like to analyse. File should be in the trk format/home/sofya/RNF/NOVOKOV/Diffusion/DTI/cst_1358.trk\n",
      "imported tractography data:/home/sofya/RNF/NOVOKOV/Diffusion/DTI/cst_1358.trk\n"
     ]
    }
   ],
   "source": [
    "# reads the tractography data in trk format\n",
    "# extracts streamlines and the file header. Streamlines should be in the same coordinate system as the FA map (used later).\n",
    "# input example: '/home/sofya/RNF/NOVOKOV/Diffusion/DTI/CST_6.trk'\n",
    "tractography_file=input(\"Please, specify the file with tracts that you would like to analyse. File should be in the trk format\")\n",
    "\n",
    "streams, hdr = load_trk(tractography_file)\n",
    "streams_array=np.asarray(streams)\n",
    "print ('imported tractography data:'+tractography_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, specify the T1fs_conform image that has been generated during head meshing procedure/home/sofya/RNF/NOVOKOV/T1/m2m_NOVIKOV/T1fs_conform.nii.gz\n",
      "Please, specify the FA image that has been generated during head meshing procedure/home/sofya/RNF/NOVOKOV/Diffusion/DTI/dti_fa.nii\n",
      "loaded T1fs_conform.nii and FA images\n"
     ]
    }
   ],
   "source": [
    "# load T1fs_conform image that operates in the same coordinates as simnibs except for the fact the center of mesh \n",
    "# is located at the image center\n",
    "# T1fs_conform image should be generated in advance during the head meshing procedure\n",
    "# input example: fname_T1='/home/sofya/RNF/NOVOKOV/T1/m2m_NOVIKOV/T1fs_conform.nii.gz'\n",
    "\n",
    "fname_T1=input(\"Please, specify the T1fs_conform image that has been generated during head meshing procedure\")\n",
    "data_T1, affine_T1 = load_nifti(fname_T1)\n",
    "\n",
    "# load FA image in the same coordinates as tracts\n",
    "# input example:fname_FA='/home/sofya/RNF/NOVOKOV/Diffusion/DTI/dti_fa.nii'\n",
    "fname_FA=input(\"Please, specify the FA image that has been generated during head meshing procedure\")\n",
    "data_FA, affine_FA = load_nifti(fname_FA)\n",
    "\n",
    "print ('loaded T1fs_conform.nii and FA images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, specify the head mesh file/home/sofya/Example_data/subject.msh\n",
      "Please, specify the directory where you would like to save your simulation results/home/sofya/Example_data/Output\n"
     ]
    }
   ],
   "source": [
    "# specify the head mesh file that is used later in simnibs to simulate induced electric field\n",
    "# input example:'/media/sofya/Seagate Backup Plus Drive/NOVOKOV/T1/NOVIKOV.msh'\n",
    "mesh_path=input(\"Please, specify the head mesh file\")\n",
    "\n",
    "last_slach=max([i for i, ltr in enumerate(mesh_path) if ltr == '/'])+1\n",
    "subject_name=mesh_path[last_slach:-4]\n",
    "\n",
    "# specify the directory where you would like to save your simulation results\n",
    "# input example:'/media/sofya/Seagate Backup Plus Drive/NOVOKOV/T1/StimVis'\n",
    "out_dir=input(\"Please, specify the directory where you would like to save your simulation results\")\n",
    "out_dir=out_dir+'/simulation_at_pos_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated c_of_mass transformation\n",
      "Optimizing level 2 [max iter: 10000]\n",
      "Optimizing level 1 [max iter: 1000]\n",
      "Optimizing level 0 [max iter: 100]\n",
      "calculated 3D translation transform\n",
      "Optimizing level 2 [max iter: 10000]\n",
      "Optimizing level 1 [max iter: 1000]\n",
      "Optimizing level 0 [max iter: 100]\n",
      "calculated Rigid 3D transform\n",
      "Optimizing level 2 [max iter: 10000]\n",
      "Optimizing level 1 [max iter: 1000]\n",
      "Optimizing level 0 [max iter: 100]\n",
      "calculated Affine 3D transform\n"
     ]
    }
   ],
   "source": [
    "# Co-registration of T1fs_conform and FA images. Performed in 4 steps.\n",
    "# Step 1. Calculation of the center of mass transform. Used later as starting transform.\n",
    "c_of_mass = transform_centers_of_mass(data_T1, affine_T1,\n",
    "                                      data_FA, affine_FA)\n",
    "print ('calculated c_of_mass transformation')\n",
    "\n",
    "# Step 2. Calculation of a 3D translation transform. Used in the next step as starting transform.\n",
    "nbins = 32\n",
    "sampling_prop = None\n",
    "metric = MutualInformationMetric(nbins, sampling_prop)\n",
    "level_iters = [10000, 1000, 100]\n",
    "sigmas = [3.0, 1.0, 0.0]\n",
    "factors = [4, 2, 1]\n",
    "affreg = AffineRegistration(metric=metric,\n",
    "                            level_iters=level_iters,\n",
    "                            sigmas=sigmas,\n",
    "                            factors=factors)\n",
    "\n",
    "transform = TranslationTransform3D()\n",
    "params0 = None\n",
    "starting_affine = c_of_mass.affine\n",
    "translation = affreg.optimize(data_T1, data_FA, transform, params0,\n",
    "                              affine_T1, affine_FA,\n",
    "                              starting_affine=starting_affine)\n",
    "print ('calculated 3D translation transform')\n",
    "\n",
    "# Step 3. Calculation of a Rigid 3D transform. Used in the next step as starting transform\n",
    "transform = RigidTransform3D()\n",
    "params0 = None\n",
    "starting_affine = translation.affine\n",
    "rigid = affreg.optimize(data_T1, data_FA, transform, params0,\n",
    "                        affine_T1, affine_FA,\n",
    "                        starting_affine=starting_affine)\n",
    "print ('calculated Rigid 3D transform')\n",
    "\n",
    "# Step 4. Calculation of an affine transform. Used for co-registration of T1 and FA images. \n",
    "transform = AffineTransform3D()\n",
    "params0 = None\n",
    "starting_affine = rigid.affine\n",
    "affine = affreg.optimize(data_T1, data_FA, transform, params0,\n",
    "                        affine_T1, affine_FA,\n",
    "                        starting_affine=starting_affine)\n",
    "\n",
    "print ('calculated Affine 3D transform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = np.eye(4)\n",
    "\n",
    "inv_affine_FA=np.linalg.inv(affine_FA)\n",
    "inv_affine_T1=np.linalg.inv(affine_T1)\n",
    "inv_affine=np.linalg.inv(affine.affine) \n",
    "\n",
    "# transforming streamlines to FA space\n",
    "new_streams_FA=streamline.transform_streamlines(streams, inv_affine_FA)\n",
    "new_streams_FA_array=np.asarray(new_streams_FA)\n",
    "\n",
    "T1_to_FA=np.dot(inv_affine_FA, np.dot(affine.affine, affine_T1)) \n",
    "FA_to_T1=np.linalg.inv(T1_to_FA)\n",
    "\n",
    "# transforming streamlines from FA to T1 space\n",
    "new_streams_T1=streamline.transform_streamlines(new_streams_FA, FA_to_T1)\n",
    "new_streams_T1_array=np.asarray(new_streams_T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # исключительно для визуализации и в DAMDID\n",
    "all_new_streams_T1 = streamline.transform_streamlines(new_streams_FA, FA_to_T1)\n",
    "all_new_streams_T1_array = np.asarray(all_new_streams_T1)\n",
    "\n",
    "new_streams_T1 = []\n",
    "selected_fibers = [73, 170, 172, 208, 210, 211, 255, 261, 263, 700, 701, 773] \n",
    "for good_fiber in selected_fibers :\n",
    "    new_streams_T1.append(all_new_streams_T1_array[good_fiber])\n",
    "\n",
    "new_streams_T1_array = np.asarray(new_streams_T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to compute 1st-order numerical derivative using a 3-point schema\n",
    "# t - a point (index in the 'line' array) at which derivative should be computed\n",
    "# line - array representing a function\n",
    "# h - step between the points on the line\n",
    "\n",
    "def my_deriv(t,line,h=1):\n",
    "    if t==0:\n",
    "        return (-3*line[t]+4*line[t+1]-line[t+2])/(2*h)\n",
    "    elif t==len(line)-1:\n",
    "        return (line[t-2]-4*line[t-1]+3*line[t])/(2*h)\n",
    "    else:\n",
    "        return (line[t+1]-line[t-1])/(2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating amline derivatives\n"
     ]
    }
   ],
   "source": [
    "# calculating amline derivatives along the streamlines to get the local orientation of the streamlines\n",
    "\n",
    "streams_array_derivative=copy.deepcopy(new_streams_T1_array)\n",
    "\n",
    "print ('calculating amline derivatives')\n",
    "for stream in range(len(new_streams_T1_array)):\n",
    "    my_steam=new_streams_T1_array[stream]\n",
    "    for t in range(len(my_steam[:,0])):\n",
    "        streams_array_derivative[stream][t,0]=my_deriv(t,my_steam[:,0])\n",
    "        streams_array_derivative[stream][t,1]=my_deriv(t,my_steam[:,1])\n",
    "        streams_array_derivative[stream][t,2]=my_deriv(t,my_steam[:,2])\n",
    "        deriv_norm=np.linalg.norm(streams_array_derivative[stream][t,:])\n",
    "        streams_array_derivative[stream][t,:]=streams_array_derivative[stream][t,:]/deriv_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to run simulations of the induced magnetic field using simnibs software\n",
    "\n",
    "def simulation(fnamehead, pathfem, pos_centre=[-74.296158, -10.213354, 28.307243], pos_ydir=[-74.217369, -37.293205, 20.05232], distance=4, current_change=1e6):\n",
    "    # Initalize a session\n",
    "    s = sim_struct.SESSION()\n",
    "    # Name of head mesh\n",
    "    s.fnamehead = fnamehead\n",
    "    # Output folder\n",
    "    s.pathfem = pathfem\n",
    "    # Not to visualize results in gmsh when running simulations (else set to True)\n",
    "    s.open_in_gmsh=False\n",
    "    \n",
    "    # Initialize a list of TMS simulations\n",
    "    tmslist = s.add_tmslist()\n",
    "    # Select coil. For full list of available coils, please see simnibs documentation\n",
    "    tmslist.fnamecoil = 'Magstim_70mm_Fig8.nii.gz'\n",
    "    \n",
    "    # Initialize a coil position\n",
    "    pos = tmslist.add_position()\n",
    "    pos.centre = pos_centre # Place the coil over\n",
    "    pos.pos_ydir = pos_ydir # Point the coil towards\n",
    "    pos.distance = distance # Distance between coil and head\n",
    "    pos.didt = current_change # Rate of change of current in the coil, in A/s.\n",
    "    run_simnibs(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_streams_T1=list(new_streams_T1)\n",
    "# adding one fictive bundle of length 1 with coordinates [0,0,0] to avoid some bugs with actor.line during visualization\n",
    "list_streams_T1.append(np.array([0,0,0]))\n",
    "\n",
    "bundle_native = list_streams_T1\n",
    "\n",
    "# generating a list of colors to visualize later the stimualtion effects\n",
    "effect_max=+1000000\n",
    "effect_min=-1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%cython -a\n",
    "def load_elems(nodes,elems):\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    elems = elems[elems[:,3]!= -1,:]\n",
    "    # Computing rectangles\n",
    "    tmp = nodes[elems-1,:]\n",
    "    elems_min = tmp.min(axis=1)\n",
    "    elems_max = tmp.max(axis=1)\n",
    "    tmp = 0\n",
    "    sizes = (elems_max-elems_min).max(axis=0)\n",
    "    # It is the index to reduce the elements to check\n",
    "    order_min = np.argsort(elems_min[:,0])\n",
    "    return {\"Nodes\":nodes, \"Elems\":elems, \"El_min\":elems_min, \"El_max\":elems_max, \"Sizes\":sizes,\"Order_min\":order_min}\n",
    "\n",
    "def get_ttrd(loaded_elems,point):\n",
    "    import numpy as np\n",
    "    # Just to use names I have used before\n",
    "    nodes = loaded_elems[\"Nodes\"]\n",
    "    elems = loaded_elems[\"Elems\"]\n",
    "    elems_min = loaded_elems[\"El_min\"]\n",
    "    elems_max = loaded_elems[\"El_max\"]\n",
    "    sizes = loaded_elems[\"Sizes\"]\n",
    "    order_min = loaded_elems[\"Order_min\"]\n",
    "    \n",
    "    # Binary search to reduce the iterating points from 4mln to around 200k.\n",
    "    r = np.searchsorted(elems_min[:,0],point[0],side='left',sorter=order_min)\n",
    "    l = np.searchsorted(elems_min[:,0],point[0] - sizes[0],side='right',sorter=order_min)\n",
    "    # Projection the data to only these points\n",
    "    e_max = elems_max[order_min[l:r]]\n",
    "    e_min = elems_min[order_min[l:r]]\n",
    "    \n",
    "    # Checks which ttrds are possible to contain the point\n",
    "    potential_ttrds = order_min[l:r][(point[0] <= e_max[:,0]) & (e_min[:,1]<= point[1]) & (point[1] <= e_max[:,1]) & (e_min[:,2]<= point[2]) & (point[2] <= e_max[:,2])]\n",
    "    \n",
    "    # It checks if the ttrd contains the point\n",
    "    def check_ttrd(ttrd, point):\n",
    "        coord = np.column_stack((ttrd[1,:]-ttrd[0,:],ttrd[2,:]-ttrd[0,:],ttrd[3,:]-ttrd[0,:]))\n",
    "        coord = np.linalg.inv(coord).dot(point-ttrd[0,:])\n",
    "        return coord.min() >= 0 and coord.sum() <= 1\n",
    "    # It checks if the ttrd with num ttrdNum contains the point\n",
    "    def check_ttrd_byNum(ttrdNum, point):\n",
    "        ttrd = nodes[elems[ttrdNum]-1]\n",
    "        return check_ttrd(ttrd,point)\n",
    "    \n",
    "    # Just takes all ttrds that contain points\n",
    "    nodeIndices = elems[[x for x in potential_ttrds if check_ttrd_byNum(x,point)]][0]; \n",
    "    ns = nodes[nodeIndices-1]\n",
    "\n",
    "    norms = np.sum((ns-point)**2,axis=-1)**0.5\n",
    "    weights = 1/(norms+1e-10)\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    return {\"Nodes\":nodeIndices,\"Weights\":weights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to get e-field vector at a given position [x,y,z]\n",
    "def get_field(ttt, point, my_field):\n",
    "    best_ttt=get_ttrd(ttt,point)\n",
    "    return np.dot(my_field[best_ttt['Nodes']-1].T, best_ttt['Weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to calculate directional derivatives of the effective field at a given point [x,y,z]\n",
    "def deriv_e_field(coordinates, e_field_nodes, LSD, ttt):\n",
    "   \n",
    "    step=0.05\n",
    "\n",
    "    x1=coordinates[0]\n",
    "    y1=coordinates[1]\n",
    "    z1=coordinates[2]\n",
    "    x0=coordinates[0]-step\n",
    "    x2=coordinates[0]+step\n",
    "    y0=coordinates[1]-step\n",
    "    y2=coordinates[1]+step\n",
    "    z0=coordinates[2]-step\n",
    "    z2=coordinates[2]+step\n",
    "\n",
    "    f_x0_y1_z1=np.dot(get_field(ttt,np.asarray([x0,y1,z1]), e_field_nodes), LSD)\n",
    "    f_x2_y1_z1=np.dot(get_field(ttt,np.asarray([x2,y1,z1]), e_field_nodes), LSD)\n",
    "    f_x1_y1_z1=np.dot(get_field(ttt,np.asarray([x1,y1,z1]), e_field_nodes), LSD)\n",
    "    f_x1_y0_z1=np.dot(get_field(ttt,np.asarray([x1,y0,z1]), e_field_nodes), LSD)\n",
    "    f_x1_y2_z1=np.dot(get_field(ttt,np.asarray([x1,y2,z1]), e_field_nodes), LSD)\n",
    "    f_x1_y1_z0=np.dot(get_field(ttt,np.asarray([x1,y1,z0]), e_field_nodes), LSD)\n",
    "    f_x1_y1_z2=np.dot(get_field(ttt,np.asarray([x1,y1,z2]), e_field_nodes), LSD)\n",
    "    \n",
    "    gradx=my_deriv(1,[f_x0_y1_z1,f_x1_y1_z1,f_x2_y1_z1], step)\n",
    "    grady=my_deriv(1,[f_x1_y0_z1,f_x1_y1_z1,f_x1_y2_z1], step)\n",
    "    gradz=my_deriv(1,[f_x1_y1_z0,f_x1_y1_z1,f_x1_y1_z2], step)\n",
    "    \n",
    "    return np.dot([gradx, grady, gradz], LSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to compute the TMS effects for a given coil position and coil direction\n",
    "def change_TMS_effects(x,y,z, x_dir, y_dir, z_dir):\n",
    "    \n",
    "    l = 2 # membrane space constant 2mm\n",
    "    l2 = l**2\n",
    "    effect_max = -1000000\n",
    "\n",
    "    position = [x - 256/2, y - 256/2, z - 256/2]\n",
    "    direction = [x_dir - 256/2, y_dir - 256/2, z - 256/2]\n",
    "    current_out_dir = out_dir + str(x) + '_' + str(y) + '_' + str(z)\n",
    "    simulation(mesh_path,current_out_dir,pos_centre=position, pos_ydir=direction)\n",
    "    \n",
    "    mesh_file = current_out_dir+'/'+subject_name+'_TMS_1-0001_Magstim_70mm_Fig8_nii_scalar.msh'\n",
    "    field_mesh = simnibs.msh.read_msh(mesh_file)\n",
    "    field_as_nodedata = field_mesh.elmdata[0].as_nodedata()\n",
    "    field_at_nodes = field_as_nodedata.value\n",
    "    \n",
    "    ttt = load_elems(field_mesh.nodes.node_coord, field_mesh.elm.node_number_list)\n",
    "    \n",
    "    effective_field=copy.deepcopy(new_streams_T1_array)\n",
    "    \n",
    "    for stream in range(len(new_streams_T1_array)):\n",
    "        my_steam = copy.deepcopy(new_streams_T1_array[stream])\n",
    "        print ('starting _' + str(stream) + ' out of ' + str(len(new_streams_T1_array)))\n",
    "        for t in range(len(my_steam[:, 0])):\n",
    "            #-256/2 because of a freesurfer RAS coordinate system\n",
    "            x = my_steam[t, 0] - 256/2\n",
    "            y = my_steam[t, 1] - 256/2\n",
    "            z = my_steam[t, 2] - 256/2\n",
    "            xyz=np.asarray([x, y, z])\n",
    "\n",
    "            field_vector_xyz = get_field(ttt, xyz, field_at_nodes)\n",
    "\n",
    "            effective_field[stream][t,0] = l*np.dot(field_vector_xyz,streams_array_derivative[stream][t,:]) \n",
    "            effective_field[stream][t,1] = l2*deriv_e_field(xyz,field_at_nodes,streams_array_derivative[stream][t,:],ttt)\n",
    "            effective_field[stream][t,2] = effective_field[stream][t,0]+effective_field[stream][t,1]\n",
    "            if (effective_field[stream][t,2] > effect_max):\n",
    "                effect_max=effective_field[stream][t,2]\n",
    "            \n",
    "    with open(current_out_dir + '/' + subject_name + '_effective_field_correct_12.txt', 'wb') as f:\n",
    "        pickle.dump(effective_field, f)\n",
    "    f.close()\n",
    "\n",
    "    return effect_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
